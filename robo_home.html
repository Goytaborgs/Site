<!DOCTYPE html>
<html lang="pt-br">
  <head>
    <title>Goytaborgs</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="css/reset.css" />
    <link rel="stylesheet" href="css/bootstrap.min.css" />
    <link rel="stylesheet" href="css/index.css" />
    <link rel="stylesheet" href="css/robo_home.css" />
    <link rel="icon" href="images/svg/logo 1.svg" />
    <link rel="stylesheet" href="css/bootstrap-icons.css" />
    <link href="css/all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/mobile.css" />
  </head>
  <body id="body">
    <header>
      <div id="nav-placeholder"></div>
    </header>
    <main>
      <section class="introduction">
        <h1>RoboHome</h1>
        <img src="images/robos/robohome.jpeg" alt="" width="20%" height="15%" />
      </section>
      <section class="mechanical_structure">
        <h2>Mechanical Structure</h2>
        <p>
          Enable Robo@home to move seamlessly in all directions, offering
          exceptional maneuverability in tight spaces. They ensure precise
          movement, allowing the robot to navigate obstacles and deliver
          medication efficiently.
        </p>
      </section>
      <section class="sensors">
        <h2>Sensors</h2>
        <p>
          The Lidar uses a rotating laser sensor to perform 360-degree scans,
          providing precise mapping and obstacle detection. It operates
          efficiently even in low-light conditions, ensuring safe navigation in
          indoor environments. <br />
          The camera captures high-resolution images, making it ideal for facial
          recognition and object detection. With a wide field of view and the
          ability to adapt to various lighting conditions, it is perfect for
          tasks such as identifying people and objects within the home.
        </p>
      </section>
      <section class="electronics">
        <h2>Electronics</h2>
        <p>
          The Raspberry Pi 4 acts as the main processor, enabling real-time data
          processing from sensors while supporting various systems such as
          navigation and object recognition. <br />
          The ESP32 microcontroller handles motor control, ensuring precise
          movement by managing speed and direction commands. By taking on this
          task, it reduces the processing load on the Raspberry Pi, improving
          overall efficiency.
        </p>
      </section>
      <section class="Software">
        <h2>Software</h2>
        <p>
          ROS 2 provides a robust framework for communication between
          components, facilitating real-time data processing, navigation, and
          decision-making. Its flexibility and scalability make it ideal for
          supporting future enhancements. <br />
          Using YOLO v8, the system identifies objects like furniture, doors,
          and medications in real time. This capability aids in safe navigation
          and enhances task execution. <br />
          Facial recognition ensures personalized interactions by identifying
          individuals, playing a critical role in tasks like accurate medication
          delivery and supporting users with memory-related challenges.
          <br />
          The system employs AI for natural communication in both English and
          Portuguese. It adapts to user emotions and behaviors, providing
          guidance and reassurance tailored to individual needs.
          <br />
          LiDAR-SLAM processes data from LiDAR sensors to perform Simultaneous
          Localization and Mapping. This creates detailed real-time maps,
          enabling efficient and autonomous navigation even in dynamic
          environments.
        </p>
      </section>
    </main>
    <div id="footer-placeholder"></div>

    <script src="js/bootstrap.min.js"></script>
    <script src="js/jquery.min.js"></script>
    <script src="js/navfooter.js"></script>
  </body>
</html>
